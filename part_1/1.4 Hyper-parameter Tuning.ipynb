{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Definition\n",
    "\n",
    "Hyper-parameters control the fitting behavior and are not learned from data.\n",
    "\n",
    "```\n",
    "estimator.get_params()\n",
    "```\n",
    "\n",
    "If you think of your estimator as a black-box, hyper-parameters are knobs on the outside of the box.\n",
    "The goal of *hyper-parameter tuning* is to set the nobs to get optimal performance.\n",
    "\n",
    "<img src=\"img/hp-tuning-two-knobs.jpg\">\n",
    "<div style=\"text-align: right\">Source: Wikipedia</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why hyper-parameters?\n",
    "\n",
    "HPs control the fitting behavior thus they \"guide\" the model search. You can think of this guidance as injecting *bias* into the model. \n",
    "\n",
    "<img src=\"img/eslii-mdl-search.png\" style=\"width:400px;\">\n",
    "<div style=\"text-align: right\">Source: T. Hastie et al. (2017) \"Elements of Statistical Learning (Ed. 2)\"</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Examples\n",
    "\n",
    "`sklearn.svm.SVC`\n",
    "  * C ... complexity, higher C means more variance can be captured.\n",
    "  * gamma ... width of the RBF kernel, higher means more smoothness bias.\n",
    "  \n",
    "`sklearn.ensemble.RandomForestClassifier`\n",
    "  * max_depth ... the deeper the trees the more variance we can capture.\n",
    "  * n_features ... the more de-correlated trees, the more variance reduction (but the more trees needed).\n",
    "  \n",
    "`sklearn.linear_model.Ridge`\n",
    "  * alpha ... penalty on the L2 norm of the model coefficients, higher alpha more bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyper-parameter Tuning\n",
    "\n",
    "*Grid Search* \n",
    "\n",
    "    Defacto standard method for tuning hyper-parameters in the past decades.\n",
    "    \n",
    "    \n",
    "*Random Search*\n",
    "\n",
    "    Explore the hyper-parameter space randomly by drawing samples. \n",
    "    Good for high-dimensional spaces (e.g. DNN).\n",
    "    \n",
    "    \n",
    "<img src=\"img/bergstra12-grid-vs-rand.png\" style=\"width:600px;\">\n",
    "<div style=\"text-align: right\">Source: J. Bergstra and Y. Bengio (2012) \"Random Search for Hyper-Parameter Optimization\"</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# When is Grid Search not a good fit?\n",
    "<img src=\"img/hp-tuning-many-knobs.jpg\" >\n",
    "<div style=\"text-align: right\">Source: Wikipedia</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyper-parameter Tuning in Scikit-learn\n",
    "\n",
    "A search consists of:\n",
    "\n",
    "  * an estimator (regressor or classifier such as `sklearn.svm.SVC()`);\n",
    "  * a parameter space (e.g. `{'gamma': [0.01, 0.1, 1.0]}`);\n",
    "  * a method for searching or sampling candidates;\n",
    "  * a cross-validation scheme; and\n",
    "  * a score function (e.g. `sklearn.metrics.accuracy_score`).\n",
    "  \n",
    "## Classes\n",
    "\n",
    "  * `GridSearchCV`\n",
    "  * `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:28:43.907651Z",
     "start_time": "2020-06-18T08:28:43.081468Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description\n",
      "----------\n",
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n",
      "model score: 3.791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "data = load_boston()\n",
    "print(\"Description\\n{}\\n{}\".format('-' * 10, data.DESCR))\n",
    "X = data.data\n",
    "y = data.target\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "est = SVR()\n",
    "\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "print(\"model score: %.3f\" % mean_absolute_error(y_test, est.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:30:00.702339Z",
     "start_time": "2020-06-18T08:30:00.220452Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "model score: 3.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "est = SVR()\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [0.1, 1, 10, 100], 'kernel': ['linear']},\n",
    "  {'C': [0.1, 1, 10, 100], 'gamma': [0.1, 0.01], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "gs = GridSearchCV(est, param_grid, cv=3, scoring='neg_mean_absolute_error', verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"best params: {}\".format(gs.best_params_))\n",
    "print(\"model score: %.3f\" % mean_absolute_error(y_test, gs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:30:12.063187Z",
     "start_time": "2020-06-18T08:30:11.180683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'C': 49.88720138545616, 'gamma': 0.18083692319941533, 'kernel': 'rbf'}\n",
      "model score: 2.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "est = SVR()\n",
    "\n",
    "param_grid = {\n",
    "    'C': scipy.stats.expon(scale=100), \n",
    "    'gamma': scipy.stats.expon(scale=.1), \n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "gs = RandomizedSearchCV(est, param_grid, cv=3, scoring='neg_mean_absolute_error', \n",
    "                        n_iter=12, verbose=1, random_state=0)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"best params: {}\".format(gs.best_params_))\n",
    "print(\"model score: %.3f\" % mean_absolute_error(y_test, gs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:30:19.010488Z",
     "start_time": "2020-06-18T08:30:18.269109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import scipy\n",
    "dist = scipy.stats.expon(scale=100)\n",
    "_ = plt.hist(dist.rvs(1000), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tuning Shortcuts\n",
    "\n",
    "### Fit-once-evaluate-many\n",
    "\n",
    "Some models allow us to evaluate many hyper-parameter settings in a single fit. \n",
    "Examples: n_estimators in `RandomForest` and `GradientBoosting`; \"regularization path\" in linear models.\n",
    "    \n",
    "### Warm-starts\n",
    "\n",
    "Some models converge faster when warm started from a previous solution (with different HP settings). See [warm_start](https://scikit-learn.org/stable/glossary.html#term-warm-start) in sklearn.\n",
    "    \n",
    "### Heuristics\n",
    "\n",
    "For some hyper-parameters, good values or ranges can be compute via heuristics.\n",
    "Example: `gamma='auto'` in RBF kernel. \n",
    "    \n",
    "### Sub-sampling\n",
    "\n",
    "For some hyper-parameters, we can probe for good values on a subset of the data. Be cautious though!\n",
    "Example: `learning_rate` in SGD."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
